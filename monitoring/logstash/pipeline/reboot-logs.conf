# Logstash Pipeline Configuration for Reboot Media
# Processes application logs, access logs, and business events

input {
  # Application logs from Filebeat
  beats {
    port => 5044
    ssl => true
    ssl_certificate => "/usr/share/logstash/config/certs/logstash.crt"
    ssl_key => "/usr/share/logstash/config/certs/logstash.key"
    ssl_certificate_authorities => ["/usr/share/logstash/config/certs/ca.crt"]
  }

  # Direct application logs via HTTP
  http {
    port => 8080
    codec => "json"
    ssl => true
    ssl_certificate => "/usr/share/logstash/config/certs/logstash.crt"
    ssl_key => "/usr/share/logstash/config/certs/logstash.key"
  }

  # Syslog for system logs
  syslog {
    port => 5514
    ssl_enable => true
    ssl_cert => "/usr/share/logstash/config/certs/logstash.crt"
    ssl_key => "/usr/share/logstash/config/certs/logstash.key"
  }
}

filter {
  # Parse different log types based on source
  if [fields][log_type] == "application" {
    # Parse JSON application logs
    if [message] =~ /^\{.*\}$/ {
      json {
        source => "message"
      }
    }

    # Parse custom application log format
    if [service] == "reboot-backend" {
      grok {
        match => { 
          "message" => "%{TIMESTAMP_ISO8601:timestamp} \[%{LOGLEVEL:level}\] %{DATA:logger} - %{GREEDYDATA:log_message}"
        }
      }

      # Extract performance metrics from backend logs
      if [log_message] =~ /Response time:/ {
        grok {
          match => {
            "log_message" => "Response time: %{NUMBER:response_time:float}ms, Method: %{WORD:http_method}, Path: %{URIPATH:request_path}"
          }
        }
        
        mutate {
          add_field => { "metric_type" => "performance" }
        }
      }

      # Extract business events
      if [log_message] =~ /Lead submitted:/ {
        grok {
          match => {
            "log_message" => "Lead submitted: ID=%{WORD:lead_id}, Source=%{WORD:lead_source}, Score=%{NUMBER:lead_score:int}"
          }
        }
        
        mutate {
          add_field => { "metric_type" => "business" }
          add_field => { "event_type" => "lead_submission" }
        }
      }
    }

    # Parse frontend logs
    if [service] == "reboot-frontend" {
      # Parse Core Web Vitals data
      if [log_message] =~ /Core Web Vitals:/ {
        grok {
          match => {
            "log_message" => "Core Web Vitals: LCP=%{NUMBER:lcp:float}, CLS=%{NUMBER:cls:float}, FID=%{NUMBER:fid:float}"
          }
        }
        
        mutate {
          add_field => { "metric_type" => "web_vitals" }
        }
      }

      # Parse conversion tracking
      if [log_message] =~ /Conversion event:/ {
        grok {
          match => {
            "log_message" => "Conversion event: Type=%{WORD:conversion_type}, Value=%{NUMBER:conversion_value:float}, Source=%{WORD:conversion_source}"
          }
        }
        
        mutate {
          add_field => { "metric_type" => "conversion" }
        }
      }
    }
  }

  # Parse NGINX access logs
  if [fields][log_type] == "access" {
    grok {
      match => { 
        "message" => "%{NGINXACCESS}"
      }
    }

    # Extract user agent information
    useragent {
      source => "agent"
      target => "user_agent"
    }

    # GeoIP lookup
    geoip {
      source => "clientip"
      target => "geoip"
    }

    # Calculate page load time from X-Response-Time header
    if [http_x_response_time] {
      mutate {
        convert => { "http_x_response_time" => "float" }
        add_field => { "metric_type" => "access" }
      }
    }

    # Identify bot traffic
    if [user_agent][device] == "Spider" {
      mutate {
        add_field => { "traffic_type" => "bot" }
      }
    } else {
      mutate {
        add_field => { "traffic_type" => "human" }
      }
    }

    # Extract UTM parameters from request URI
    if [request] =~ /utm_/ {
      grok {
        match => {
          "request" => ".*utm_source=(?<utm_source>[^&\s]+)"
        }
        tag_on_failure => []
      }
      grok {
        match => {
          "request" => ".*utm_medium=(?<utm_medium>[^&\s]+)"
        }
        tag_on_failure => []
      }
      grok {
        match => {
          "request" => ".*utm_campaign=(?<utm_campaign>[^&\s]+)"
        }
        tag_on_failure => []
      }
    }
  }

  # Parse security logs
  if [fields][log_type] == "security" {
    if [log_message] =~ /Authentication failed/ {
      grok {
        match => {
          "log_message" => "Authentication failed for IP: %{IP:failed_auth_ip}, Attempts: %{NUMBER:attempt_count:int}"
        }
      }
      
      mutate {
        add_field => { "security_event" => "auth_failure" }
        add_field => { "severity" => "warning" }
      }

      # GeoIP for failed authentication attempts
      geoip {
        source => "failed_auth_ip"
        target => "threat_geoip"
      }
    }

    if [log_message] =~ /Rate limit exceeded/ {
      grok {
        match => {
          "log_message" => "Rate limit exceeded for IP: %{IP:rate_limit_ip}, Endpoint: %{URIPATH:rate_limit_endpoint}"
        }
      }
      
      mutate {
        add_field => { "security_event" => "rate_limit" }
        add_field => { "severity" => "info" }
      }
    }

    if [log_message] =~ /Suspicious activity/ {
      mutate {
        add_field => { "security_event" => "suspicious_activity" }
        add_field => { "severity" => "critical" }
      }
    }
  }

  # Common enrichment for all logs
  mutate {
    add_field => { 
      "environment" => "${ENVIRONMENT:production}"
      "service_version" => "${SERVICE_VERSION:unknown}"
    }
  }

  # Add timestamp
  date {
    match => [ "timestamp", "ISO8601" ]
    target => "@timestamp"
  }

  # Remove raw message after processing
  if ![_grokparsefailure] {
    mutate {
      remove_field => [ "message" ]
    }
  }

  # Add processing metadata
  mutate {
    add_field => { 
      "processed_by" => "logstash"
      "processing_timestamp" => "%{+YYYY-MM-dd'T'HH:mm:ss.SSSZ}"
    }
  }
}

output {
  # Route to different indices based on log type
  if [metric_type] == "business" {
    elasticsearch {
      hosts => ["https://elasticsearch-1:9200", "https://elasticsearch-2:9200", "https://elasticsearch-3:9200"]
      user => "${ELASTICSEARCH_USERNAME}"
      password => "${ELASTICSEARCH_PASSWORD}"
      ssl => true
      ssl_certificate_verification => true
      cacert => "/usr/share/logstash/config/certs/ca.crt"
      index => "reboot-business-events-%{+YYYY.MM.dd}"
      template_name => "reboot-business-events"
      template_pattern => "reboot-business-events-*"
      template => "/usr/share/logstash/templates/business-events-template.json"
    }
  } else if [metric_type] == "web_vitals" {
    elasticsearch {
      hosts => ["https://elasticsearch-1:9200", "https://elasticsearch-2:9200", "https://elasticsearch-3:9200"]
      user => "${ELASTICSEARCH_USERNAME}"
      password => "${ELASTICSEARCH_PASSWORD}"
      ssl => true
      ssl_certificate_verification => true
      cacert => "/usr/share/logstash/config/certs/ca.crt"
      index => "reboot-web-vitals-%{+YYYY.MM.dd}"
      template_name => "reboot-web-vitals"
      template_pattern => "reboot-web-vitals-*"
      template => "/usr/share/logstash/templates/web-vitals-template.json"
    }
  } else if [security_event] {
    elasticsearch {
      hosts => ["https://elasticsearch-1:9200", "https://elasticsearch-2:9200", "https://elasticsearch-3:9200"]
      user => "${ELASTICSEARCH_USERNAME}"
      password => "${ELASTICSEARCH_PASSWORD}"
      ssl => true
      ssl_certificate_verification => true
      cacert => "/usr/share/logstash/config/certs/ca.crt"
      index => "reboot-security-%{+YYYY.MM.dd}"
      template_name => "reboot-security"
      template_pattern => "reboot-security-*"
      template => "/usr/share/logstash/templates/security-template.json"
    }
  } else if [fields][log_type] == "access" {
    elasticsearch {
      hosts => ["https://elasticsearch-1:9200", "https://elasticsearch-2:9200", "https://elasticsearch-3:9200"]
      user => "${ELASTICSEARCH_USERNAME}"
      password => "${ELASTICSEARCH_PASSWORD}"
      ssl => true
      ssl_certificate_verification => true
      cacert => "/usr/share/logstash/config/certs/ca.crt"
      index => "reboot-access-%{+YYYY.MM.dd}"
      template_name => "reboot-access"
      template_pattern => "reboot-access-*"
      template => "/usr/share/logstash/templates/access-template.json"
    }
  } else {
    # Default application logs
    elasticsearch {
      hosts => ["https://elasticsearch-1:9200", "https://elasticsearch-2:9200", "https://elasticsearch-3:9200"]
      user => "${ELASTICSEARCH_USERNAME}"
      password => "${ELASTICSEARCH_PASSWORD}"
      ssl => true
      ssl_certificate_verification => true
      cacert => "/usr/share/logstash/config/certs/ca.crt"
      index => "reboot-application-%{+YYYY.MM.dd}"
      template_name => "reboot-application"
      template_pattern => "reboot-application-*"
      template => "/usr/share/logstash/templates/application-template.json"
    }
  }

  # Send critical events to alerting system
  if [severity] == "critical" or [security_event] == "suspicious_activity" {
    http {
      url => "http://alertmanager:9093/api/v1/alerts"
      http_method => "post"
      format => "json"
      mapping => {
        "alerts" => [{
          "labels" => {
            "alertname" => "LogBasedAlert"
            "severity" => "%{severity}"
            "service" => "%{service}"
            "security_event" => "%{security_event}"
          }
          "annotations" => {
            "summary" => "Critical event detected in logs"
            "description" => "%{log_message}"
          }
          "generatorURL" => "http://logstash:9600"
        }]
      }
    }
  }

  # Debug output (remove in production)
  if [@metadata][debug] {
    stdout {
      codec => rubydebug
    }
  }
}